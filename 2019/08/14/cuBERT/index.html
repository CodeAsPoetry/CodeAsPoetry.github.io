
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>cuBERT - CodeAsPoetry</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    
    <meta name="description" content="cuBERT/mklBERT介绍参考github工程地址 ，其中README.md有详细的指导过程，按照提示正常复现就妥。
此工程本质上利用tensorflow-C的核心库，针对显卡，则通过CUDA,"> 
    <meta name="author" content="Chengjie Pang"> 
    <link rel="alternative" href="atom.xml" title="CodeAsPoetry" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

    
<link rel="stylesheet" href="/css/diaspora.css">

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">CodeAsPoetry</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="http://yoursite.com"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">cuBERT</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">cuBERT</h1>
        <div class="stuff">
            <span>八月 14, 2019</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/BERT%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/" rel="tag">BERT推理加速</a></li></ul>


        </div>
        <div class="content markdown">
            <h2 id="cuBERT-mklBERT介绍"><a href="#cuBERT-mklBERT介绍" class="headerlink" title="cuBERT/mklBERT介绍"></a>cuBERT/mklBERT介绍</h2><p><a href="https://github.com/zhihu/cuBERT" target="_blank" rel="noopener">参考github工程地址</a> ，其中README.md有详细的指导过程，按照提示正常复现就妥。</p>
<p>此工程本质上利用tensorflow-C的核心库，针对显卡，则通过CUDA定制优化；针对CPU，则通过英特尔MKL定制优化。专门为BERT模型加速推理，而无需改动tensorflow框架以及代码层的结构。</p>
<p>因为绝大多数公司出于成本的考虑，在部署BERT模型时，都会选择CPU部署方式，因此CPU上BERT的推理加速就显得格外重要。<a id="more"></a>训练往往在显卡上，因为随着模型越来越复杂、参数越来越多，训练阶段极大耗时，且不仅有前向推理，还有梯度反向计算，简单比较，不难发现其实部署到CPU，在测试阶段加速前向推理更有价值。因此，本文主要介绍mklBERT。</p>
<p>关于MKL，参考的资料有：</p>
<ul>
<li><a href="https://www.cnblogs.com/bonelee/p/8327905.html" target="_blank" rel="noopener">博客</a> </li>
<li><a href="https://tensorflow.google.cn/guide/performance/overview" target="_blank" rel="noopener">Tensorflow官方API性能提升部分涉及到MKL加速</a></li>
<li><a href="https://software.intel.com/zh-cn/articles/introducing-dnn-primitives-in-intelr-mkl" target="_blank" rel="noopener">Intel官网MKL资料</a></li>
</ul>
<p><em>_MKL加速原理_</em>：在英特尔® 数学核心函数库(MKL)中引入深度神经网络(DNN)基元，应用于深度学习框架，确保通用构建模块的高效实施。这些 DNN 拓扑依靠大量的标准构建模块或基元，对以多维张量集表示的数据进行计算。这些基元包括卷积、归一化、激活和内积函数，以及处理张量所需的函数。在英特尔架构上高效执行计算需要通过向量化利用 SIMD 指令并通过线程利用多个计算内核。向量化非常重要，因为现代处理器在最多 512 位长(16 个单精度数字)的数据向量上进行运算，并且每个周期最多可执行两个乘法和加法(融合乘加或 FMA)运算。利用向量化需要将数据连续定位在内存中。由于张量的尺寸通常较小，所以更改数据布局会带来巨大的开销；设法在拓扑中执行所有运算，同时不更改不同基元的数据布局。</p>
<p>英特尔 MKL 为使用最广泛的运算(针对适用于矢量化的数据布局实施)提供了基元，具体有，直接批量卷积；内积；池化：最大值、最小值、平均值；标准化：跨渠道的本地响应标准化 (LRN)、批次规标准化；激活：修正线性单元 (ReLU)；数据操作：多维转置(转换)、拆分、合并、求和和缩放。</p>
<p>使用 TensorFlow 中现成的池分配器开发了一款自定义池分配器，自定义池分配器确保了 TensorFlow 和英特尔 MKL 共享相同的内存池(使用英特尔 MKL imalloc 功能)，不必过早地将内存返回至操作系统，因此避免了昂贵的页面缺失和页面清除。此外，优化了多个线程库(TensorFlow 使用的 pthread 和英特尔 MKL 使用的 OpenMP)，使它们能共存，而不是互相争夺 CPU 资源。(解释了下面测试加速效果实验中，使用mkl加速的mklBERT占用更大的内存，能够更多的占有CPU计算资源。)批处理大小会影响可用并行性、工作集大小和总体内存性能的另一个重要参数。(这解释了实验结果中由批处理大小的设置导致模型在资源占用上的变动。)</p>
<h2 id="工程复现"><a href="#工程复现" class="headerlink" title="工程复现"></a>工程复现</h2><p>系统：Ubuntu16.04</p>
<ul>
<li>从github上克隆工程，git clone <a href="https://github.com/zhihu/cuBERT" target="_blank" rel="noopener">https://github.com/zhihu/cuBERT</a></li>
<li>因为我的Ubuntu16.04系统自带的cmake版本较低，我需要重装，Ubuntu16.04安装最新版cmake，<a href="https://www.jianshu.com/p/f07ed9ce75e1" target="_blank" rel="noopener">参考教程</a> </li>
<li>进入工程目录，执行：mkdir build &amp;&amp; cd build</li>
<li>因为在CPU部署，执行，cmake -DCMAKE_BUILD_TYPE=Release -DcuBERT_ENABLE_MKL_SUPPORT=ON ..</li>
<li>之后，再执行，make -j4</li>
<li>执行，sudo make install</li>
<li>我们需要下载BERT模型和对应的词表，并在脚本中配置好对应路径。github给出的模型下载是Dropbox，鉴于大中华局域网，大家八仙过海，各显神通吧。</li>
<li>cd python 、执行 python setup.py bdist_wheel ，这里有个小坑，当时执行时，python使用的是3.5，执行结果是生成一个可以安装的python包，然而当时工程配置的python是3.6，然后就傻逼了。原因在命令行执行这些步骤没有切换到conda环境，执行完是在Anaconda系统的工程使用，所以一定要对应起来。</li>
<li>安装上步得到的python包，pip install dist/cuBERT-xxx.whl</li>
<li>执行工程中自带的python测试脚本</li>
</ul>
<p>出于工程需求，需要在有限的资源上对比传统的session加载ckpt模型和cuBERT/mklBERT加载pb模型分别在前向推断速度和资源占用效率。</p>
<ul>
<li>对于传统的tensorflow框架通过session加载ckpt并且run得到prediction这种方式，限制CPU核数资源：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cpu_num &#x3D; int(os.environ.get(&#39;CPU_NUM&#39;, 1))</span><br><span class="line">config &#x3D; tf.ConfigProto(device_count &#x3D; &#123;&quot;CPU&quot;: cpu_num &#125;,</span><br><span class="line">                                        Inter_op_parallelism_threads &#x3D; cpu_num,</span><br><span class="line">                                        Intra_op_parallelism_threads &#x3D; cpu_num,</span><br><span class="line">                                        log_device_placement &#x3D; True)</span><br><span class="line">with tf.Session(config &#x3D; config) as s:</span><br><span class="line">    pass</span><br></pre></td></tr></table></figure>
<ul>
<li>对于mklBERT加载pb模型，限制CPU核数资源：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">"MKL_NUM_THREADS"</span>] = <span class="string">"1"</span></span><br><span class="line">os.environ[<span class="string">"OMP_NUM_THREADS"</span>] = <span class="string">"1"</span></span><br></pre></td></tr></table></figure>
<h2 id="加速效果展示"><a href="#加速效果展示" class="headerlink" title="加速效果展示"></a>加速效果展示</h2>
            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='https://link.hhtjim.com/163/36897723.mp3'></li>
                        
                    
                        
                            <li title='1' data-url='https://link.hhtjim.com/163/643121.mp3'></li>
                        
                    
                        
                            <li title='2' data-url='https://link.hhtjim.com/163/4947848.mp3'></li>
                        
                    
                        
                            <li title='3' data-url='https://link.hhtjim.com/163/617492.mp3'></li>
                        
                    
                        
                            <li title='4' data-url='https://link.hhtjim.com/163/399367220.mp3'></li>
                        
                    
                        
                            <li title='5' data-url='https://link.hhtjim.com/163/26102241.mp3'></li>
                        
                    
                        
                            <li title='6' data-url='https://link.hhtjim.com/163/444951.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
		data-enable='true'
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d='false'
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




</html>
