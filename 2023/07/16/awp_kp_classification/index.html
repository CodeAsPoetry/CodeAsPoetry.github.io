
<!DOCTYPE html>
<html lang="en" class="loading">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AWP问题分类&amp;小学数学应用题知识点分类 - CodeAsPoetry</title>
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate" />
    
    <meta name="description" content="项目背景分析 K12 相关的教育搜索 query，包括拍照搜题上传的照片，在学科分布中，数学占比最大，呈将近一半左右。再考虑目前在 K12解题产品级应用上 NLP 模型的能力，小学数学作为入手点较为,"> 
    <meta name="author" content="Chengjie Pang"> 
    <link rel="alternative" href="atom.xml" title="CodeAsPoetry" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

    
<link rel="stylesheet" href="/css/diaspora.css">

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body class="loading">
    <span id="config-title" style="display:none">CodeAsPoetry</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="iconfont icon-home image-icon" href="javascript:;" data-url="http://yoursite.com"></a>
    <div title="播放/暂停" class="iconfont icon-play"></div>
    <h3 class="subtitle">AWP问题分类&小学数学应用题知识点分类</h3>
    <div class="social">
        <div>
            <div class="share">
                <a title="获取二维码" class="iconfont icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">AWP问题分类&小学数学应用题知识点分类</h1>
        <div class="stuff">
            <span>七月 16, 2023</span>
            
  <ul class="post-tags-list" itemprop="keywords"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/NLP/" rel="tag">NLP</a></li></ul>


        </div>
        <div class="content markdown">
            <h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>分析 K12 相关的教育搜索 query，包括拍照搜题上传的照片，在学科分布中，数学占比最大，呈将近一半左右。再考虑目前在 K12解题产品级应用上 NLP 模型的能力，小学数学作为入手点较为合适，尤为其中的算术文字题。即通过自然语言文本将问题描述清楚，通过加减乘除四则运算，便可求解答案的小学数学应用题。在 NLP 模型进行解答的前置环节，需要判定给定的题目描述是否为 AWP (算术文字题) 问题以及对应考察的知识点类型，比如“鸡兔同笼”、“和差倍”、“归一问题”、“工程问题”、“行程问题”等，便于后续的公式生成、答案生成以及解析生成等。因此是否为 AWP 问题 (二分类) 和知识点分类 (多分类多标签)，需要进行建模实现。</p>
<h2 id="项目过程"><a href="#项目过程" class="headerlink" title="项目过程"></a>项目过程</h2><p>此项目的模型实现，并不是重点和难点。二分类模型、多标签多分类模型，都是机器学习中的典型场景。唯一可能需要花些心思和精力的点是存在严重类别或标签的不平衡，进而导致长尾类别或标签分布过分稀疏被模型忽略。那么在这些长尾类别和标签上，精度和召回都会偏低。这个问题既可以通过 loss 的构建 ( focal loss、asymmetric loss)进行缓解，也可以通过稀疏类别和稀疏标签的上采样数据增强进行缓解，还可以通过难样本挖掘等进行缓解。 ( 注：Asymmetric Loss For Multi-Label Classification  论文 )</p>
<p>此项目重点和难点，在于标准定义和数据集的构建上。标准定义包括，业务目标场景归化到 AWP 问题的标准定义、AWP 问题自身的标准定义、小学数学应用题涉及的知识点多类别定义、多标签定义；数据集构建包括，AWP 问题分类训练数据集中负样本的构建、知识点分类中的不同类别、不同标签对应多少样本比例的构建，以及最终能够准确反映线上收益的测试集和评估业务指标的构建。</p>
<h3 id="标准定义"><a href="#标准定义" class="headerlink" title="标准定义"></a>标准定义</h3><h4 id="业务目标场景归化到-AWP-问题定义"><a href="#业务目标场景归化到-AWP-问题定义" class="headerlink" title="业务目标场景归化到 AWP 问题定义"></a>业务目标场景归化到 AWP 问题定义</h4><p>该项目的业务目标是针对用户上传的有解题需求的 query (包括拍照搜题)中的小学数学应用题，能够给出公式、解题步骤、答案和解析。主要收益来自于返回的自然搜索结果和拍照搜题中的题库未覆盖到的用户查询 query，或者是查询结果质量偏低，只是近似题不是原题等场景，从而利用 AI 解题能力提高用户体验。因此，将此业务目标场景归化到 AI 解答 AWP 问题。</p>
<h4 id="AWP-问题定义"><a href="#AWP-问题定义" class="headerlink" title="AWP 问题定义"></a>AWP 问题定义</h4><p>能够通过四则运算和简单的一元一次方程获取答案的数学文字题，标准细化：</p>
<ul>
<li>答案必须是数值；</li>
<li>该答案数值可以通过四则运算或一元一次方程求解得到；(大于、小于、比较、取余都作为非 AWP 问题。)</li>
<li>主要为应用题(语言或文字叙述有关事实)，有一定的场景设定，“列式计算”、“解方程”等作为非 AWP 问题，凡是需要文字以外的信息才可以作答的，“如图、如表”等，也作为非 AWP 问题；</li>
<li>多个小问需要拆开，所有子问题都是 AWP 问题，整体才可以作为 AWP 问题。</li>
</ul>
<h4 id="小学数学应用题涉及的知识点——类别定义及标签定义"><a href="#小学数学应用题涉及的知识点——类别定义及标签定义" class="headerlink" title="小学数学应用题涉及的知识点——类别定义及标签定义"></a>小学数学应用题涉及的知识点——类别定义及标签定义</h4><p>知识点体系参考来源: <a href="https://zujuan.xkw.com/xxsx/zsd132650/" target="_blank" rel="noopener">https://zujuan.xkw.com/xxsx/zsd132650/</a></p>
<p><img src="/images/zujuanwang_kp.png" alt="image"></p>
<ul>
<li>一个题目下的知识点既有应用题类型，如“归一问题”，又有“多位数与一位数的乘除混合运算”标签</li>
<li>抓取题目数据及知识点，结合目录，整理出所有知识点信息，对知识点统一进行盘点</li>
<li>梳理知识点信息，将应用题的类型和涉及知识点的标签分离开来，能归一的归一，能合并的合并<ul>
<li>梳理原则1，类别能够反映出解题公式的统一范式，比如“鸡兔同笼”、“植树问题”，一道题目也可能对应多个类别</li>
<li>梳理原则2，标签更多反映描述题目运算或者题目本身信息，标签进行归一，比如“多位数与一位数的乘除混合运算”、“多位数与一位数的加减混合运算”、“多位数与一位数的四则混合运算”，确保标签之间语义互斥，在归一后的标签体系中，一道题目可以对应零、一种或多种标签</li>
</ul>
</li>
<li>实际情况中，确实存在很难进行鉴别的 term ，是划归在类别体系还是划归在标签体系，收集有争议，模糊不清的 term，从用户 query 视角，分析用户使用这些 term 的习惯，权衡折中。进行类别和标签体系的建设，本质是为了能够将这些信息透传给下游公式生成模块，让 AI 模型能够根据类别和标签更好地生成公式。</li>
</ul>
<h3 id="数据集构建"><a href="#数据集构建" class="headerlink" title="数据集构建"></a>数据集构建</h3><h4 id="AWP-问题分类训练数据集中负样本的构建"><a href="#AWP-问题分类训练数据集中负样本的构建" class="headerlink" title="AWP 问题分类训练数据集中负样本的构建"></a>AWP 问题分类训练数据集中负样本的构建</h4><p>此样本集需要根据实际模型训练迭代情况，进行调整，大概来源几个方面：</p>
<ul>
<li>线上服务的 query (包括对照片经过 OCR 识别的到的文本)，涉及到的小学数学题目非 AWP 问题进行采样</li>
<li>非四则运算或一元一次方程能够解决的题目，包括图文、图表题目，直接列式计算、解方程的题目，涉及到比较、取余的题目</li>
<li>非小学数学题目</li>
</ul>
<h4 id="知识点分类中的不同类别、不同标签对应多少样本比例的构建"><a href="#知识点分类中的不同类别、不同标签对应多少样本比例的构建" class="headerlink" title="知识点分类中的不同类别、不同标签对应多少样本比例的构建"></a>知识点分类中的不同类别、不同标签对应多少样本比例的构建</h4><p>此样本集需要根据实际模型训练迭代情况，进行调整，大概来源几个方面：</p>
<ul>
<li>组卷网的目录数据获取、题目以及涉及的知识点获取</li>
<li>菁优网的目录数据获取、题目以及涉及的知识点获取</li>
<li>根据实际情况以及下游 AI 公式生成模块的需要，上采样或难样本挖掘某些长尾类别和标签对应的数据</li>
</ul>
<h4 id="准确反映线上收益的测试集和评估业务指标的构建"><a href="#准确反映线上收益的测试集和评估业务指标的构建" class="headerlink" title="准确反映线上收益的测试集和评估业务指标的构建"></a>准确反映线上收益的测试集和评估业务指标的构建</h4><p>由于最终应用到线上服务链路较长，下游接 AI 公式生成等模块，最终得到的结果才服务线上。故无法直接对AWP分类和知识点分类，从线上收益角度评测。所以需要分两块评估。一是线上真正需要解的 AWP 问题的召回；二是真正透传出的正确知识点信息的 AWP 题目占召回目标 AWP 题目的比例。后续结合 AI 公式生成的结果，以及最终的服务性能，做回归验证。</p>
<h2 id="代码参考"><a href="#代码参考" class="headerlink" title="代码参考"></a>代码参考</h2><h3 id="ASL-损失"><a href="#ASL-损失" class="headerlink" title="ASL 损失"></a>ASL 损失</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">torch_asl_loss</span><span class="params">(x, y)</span>:</span></span><br><span class="line">    <span class="string">""""</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    x: input logits</span></span><br><span class="line"><span class="string">    y: targets (multi-label binarized vector)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    targets = y</span><br><span class="line">    anti_targets = <span class="number">1</span> - y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculating Probabilities</span></span><br><span class="line">    xs_pos = torch.sigmoid(x)</span><br><span class="line">    xs_neg = <span class="number">1.0</span> - xs_pos</span><br><span class="line"></span><br><span class="line">    clip = <span class="number">0.05</span></span><br><span class="line">    gamma_neg = <span class="number">4</span></span><br><span class="line">    gamma_pos = <span class="number">1</span></span><br><span class="line">    disable_torch_grad_focal_loss = <span class="literal">False</span></span><br><span class="line">    eps = <span class="number">1e-8</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Asymmetric Clipping</span></span><br><span class="line">    <span class="keyword">if</span> clip <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> clip &gt; <span class="number">0</span>:</span><br><span class="line">        xs_neg.add_(clip).clamp_(max=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Basic CE calculation</span></span><br><span class="line">    loss = targets * torch.log(xs_pos.clamp(min=eps))</span><br><span class="line">    loss.add_(anti_targets * torch.log(xs_neg.clamp(min=eps)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Asymmetric Focusing</span></span><br><span class="line">    <span class="keyword">if</span> gamma_neg &gt; <span class="number">0</span> <span class="keyword">or</span> gamma_pos &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> disable_torch_grad_focal_loss:</span><br><span class="line">            torch._C.set_grad_enabled(<span class="literal">False</span>)</span><br><span class="line">        xs_pos = xs_pos * targets</span><br><span class="line">        xs_neg = xs_neg * anti_targets</span><br><span class="line">        asymmetric_w = torch.pow(<span class="number">1</span> - xs_pos - xs_neg,</span><br><span class="line">                                      gamma_pos * targets + gamma_neg * anti_targets)</span><br><span class="line">        <span class="keyword">if</span> disable_torch_grad_focal_loss:</span><br><span class="line">            torch._C.set_grad_enabled(<span class="literal">True</span>)</span><br><span class="line">        loss *= asymmetric_w</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> -loss.sum()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span><span class="params">(logits, labels, gamma_pos=<span class="number">1</span>, gamma_neg=<span class="number">4</span>, clip=<span class="number">0.05</span>, eps=<span class="number">1e-8</span>, )</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算概率 caalculating probabilities</span></span><br><span class="line">    labels = tf.cast(labels, dtype=tf.float32)</span><br><span class="line">    logits_sigmoid = tf.nn.sigmoid(logits)</span><br><span class="line">    logits_sigmoid_pos = logits_sigmoid</span><br><span class="line">    logits_sigmoid_neg = <span class="number">1</span> - logits_sigmoid_pos</span><br><span class="line"></span><br><span class="line">    <span class="comment"># asymmetric clipping</span></span><br><span class="line">    <span class="keyword">if</span> clip <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> clip &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># logits_sigmoid_neg + clip 有可能大于1</span></span><br><span class="line">        logits_sigmoid_neg = tf.clip_by_value((logits_sigmoid_neg + clip), clip_value_min=<span class="number">0</span>, clip_value_max=<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># basic cross entropy</span></span><br><span class="line">    <span class="comment"># logits_sigmoid_pos的取值范围是0-1，因此可以直接可以取对数log，不会溢出</span></span><br><span class="line">    loss_pos = labels * tf.log(tf.clip_by_value(logits_sigmoid_pos, clip_value_max=<span class="number">1.0</span>, clip_value_min=eps))</span><br><span class="line">    loss_neg = (<span class="number">1</span> - labels) * tf.log(tf.clip_by_value(logits_sigmoid_neg, clip_value_max=<span class="number">1.0</span>, clip_value_min=eps))</span><br><span class="line">    loss = loss_pos + loss_neg</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Asymmetric focusing</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> gamma_neg &gt; <span class="number">0</span> <span class="keyword">or</span> gamma_pos &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># with tf.GradientTape() as tape:</span></span><br><span class="line">        <span class="comment">#     with tape.stop_recording():</span></span><br><span class="line">        <span class="comment">#         pass</span></span><br><span class="line">        <span class="comment">#     pass</span></span><br><span class="line">        pt0 = logits_sigmoid_pos * labels</span><br><span class="line">        pt1 = logits_sigmoid_neg * (<span class="number">1</span> - labels)</span><br><span class="line">        pt = pt0 + pt1</span><br><span class="line"></span><br><span class="line">        one_sided_gamma = gamma_pos * labels + gamma_neg * (<span class="number">1</span> - labels)</span><br><span class="line">        one_sided_w = tf.pow(<span class="number">1</span> - pt, one_sided_gamma)</span><br><span class="line"></span><br><span class="line">        one_sided_w_no_gradient = tf.stop_gradient([pt0, pt1, pt, one_sided_gamma, one_sided_w])</span><br><span class="line">        loss *= one_sided_w_no_gradient</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> -tf.reduce_sum(loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_loss_own</span><span class="params">(logits, labels)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">"loss"</span>):</span><br><span class="line">        <span class="comment"># labels = tf.reshape(labels, [-1])</span></span><br><span class="line">        <span class="comment"># Calculating Probabilities</span></span><br><span class="line">        labels = tf.cast(labels, dtype=tf.float32)</span><br><span class="line">        x_sigmoid = tf.sigmoid(logits)</span><br><span class="line">        xs_pos = x_sigmoid</span><br><span class="line">        xs_neg = <span class="number">1</span> - x_sigmoid</span><br><span class="line"></span><br><span class="line">        clip = <span class="number">0.05</span></span><br><span class="line">        gamma_neg = <span class="number">4</span></span><br><span class="line">        gamma_pos = <span class="number">1</span></span><br><span class="line">        eps = <span class="number">1e-8</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Asymmetric Clipping</span></span><br><span class="line">        <span class="keyword">if</span> clip <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> clip &gt; <span class="number">0</span>:</span><br><span class="line">            xs_neg = tf.clip_by_value(xs_neg + clip, clip_value_min=<span class="number">-1</span>, clip_value_max=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        los_pos = labels * tf.log(tf.clip_by_value(xs_pos, clip_value_min=eps, clip_value_max=<span class="number">1e8</span>))</span><br><span class="line">        los_neg = (<span class="number">1</span> - labels) * tf.log(tf.clip_by_value(xs_neg, clip_value_min=eps, clip_value_max=<span class="number">1e8</span>))</span><br><span class="line">        loss = los_pos + los_neg</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Asymmetric Focusing</span></span><br><span class="line">        <span class="keyword">if</span> gamma_neg &gt; <span class="number">0</span> <span class="keyword">or</span> gamma_pos &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># if self.disable_torch_grad_focal_loss:</span></span><br><span class="line">            <span class="comment">#     torch._C.set_grad_enabled(False)</span></span><br><span class="line">            pt0 = xs_pos * labels</span><br><span class="line">            pt1 = xs_neg * (<span class="number">1</span> - labels)  <span class="comment"># pt = p if t &gt; 0 else 1-p</span></span><br><span class="line">            pt = pt0 + pt1</span><br><span class="line">            one_sided_gamma = gamma_pos * labels + gamma_neg * (<span class="number">1</span> - labels)</span><br><span class="line">            one_sided_w = tf.pow(<span class="number">1</span> - pt, one_sided_gamma)</span><br><span class="line">            <span class="comment"># if self.disable_torch_grad_focal_loss:</span></span><br><span class="line">            <span class="comment">#     torch._C.set_grad_enabled(True)</span></span><br><span class="line">            loss *= one_sided_w</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> tf.reduce_sum(-loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    logits = []</span><br><span class="line">    labels = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># tf_owner</span></span><br><span class="line">    <span class="comment"># tf_logits = tf.reshape(tf.constant(logits), [1, 334])</span></span><br><span class="line">    <span class="comment"># tf_labels = tf.reshape(tf.constant(labels), [1, 334])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># tf_loss = compute_loss_own(tf_logits, tf_labels)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># with tf.Session() as sess:</span></span><br><span class="line">    <span class="comment">#     tf.global_variables_initializer().run()</span></span><br><span class="line">    <span class="comment">#     print(sess.run(tf_loss))      # 3.1016927</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># tf CSDN</span></span><br><span class="line">    <span class="comment"># tf_logits = tf.reshape(tf.constant(logits), [1, 334])</span></span><br><span class="line">    <span class="comment"># tf_labels = tf.reshape(tf.constant(labels), [1, 334])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># tf_loss = compute_loss(tf_logits, tf_labels)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># with tf.Session() as sess:</span></span><br><span class="line">    <span class="comment">#     tf.global_variables_initializer().run()</span></span><br><span class="line">    <span class="comment">#     print(sess.run(tf_loss))     # 6.586828</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># pytorch 开源代码</span></span><br><span class="line">    <span class="comment"># torch_logits = torch.tensor(logits).expand([1, 334])</span></span><br><span class="line">    <span class="comment"># torch_labels = torch.tensor(labels).expand([1, 334])</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># print(torch_asl_loss(torch_logits, torch_labels))       # tensor(3.1017)</span></span><br></pre></td></tr></table></figure>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='https://link.hhtjim.com/163/36897723.mp3'></li>
                        
                    
                        
                            <li title='1' data-url='https://link.hhtjim.com/163/643121.mp3'></li>
                        
                    
                        
                            <li title='2' data-url='https://link.hhtjim.com/163/4947848.mp3'></li>
                        
                    
                        
                            <li title='3' data-url='https://link.hhtjim.com/163/617492.mp3'></li>
                        
                    
                        
                            <li title='4' data-url='https://link.hhtjim.com/163/399367220.mp3'></li>
                        
                    
                        
                            <li title='5' data-url='https://link.hhtjim.com/163/26102241.mp3'></li>
                        
                    
                        
                            <li title='6' data-url='https://link.hhtjim.com/163/444951.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
		data-enable='true'
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r=''
        data-o=''
        data-a=''
        data-d='false'
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/typed.js"></script>
<script src="/js/diaspora.js"></script>


<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">


<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




</html>
